{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: en_core_web_sm==2.0.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz#egg=en_core_web_sm==2.0.0 in /Users/noahcg/anaconda3/lib/python3.6/site-packages (2.0.0)\n",
      "\u001b[33mYou are using pip version 18.0, however version 19.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\n",
      "\u001b[93m    Linking successful\u001b[0m\n",
      "    /Users/noahcg/anaconda3/lib/python3.6/site-packages/en_core_web_sm -->\n",
      "    /Users/noahcg/anaconda3/lib/python3.6/site-packages/spacy/data/en_core_web_sm\n",
      "\n",
      "    You can now load the model via spacy.load('en_core_web_sm')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ! indicates a terminal command for Jupyter notebooks\n",
    "# en_core_web_sm is the name of SpaCy's English model\n",
    "!python -m spacy download en_core_web_sm\n",
    "# python -m allows you to use the proceeding module as  \n",
    "#    if you had typed out its entire path."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that there's a little printout telling you that you can load the model via the `spacy.load('en_core_web_sm')` method and argument. That means that you still have to call it within whatever program you write. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "# load the pre-trained model \n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use all of `en_core_web_sm`'s capabilities just by typing the command `nlp()`. __NOTE__: There are four English models offered by SpaCy that offer a variety of features for NLP use. In this tutorial, we'll be using the smallest, the one we've already downloaded. If you want to see more on the additional three models, look [here](https://spacy.io/models/en).\n",
    "\n",
    "__NOTE2__: There's a variety of ways to import whatever model you want to work with as well - SpaCy recommends native imports for larger code bases to make it easier to integrate models with an existing build process and workflow. It'll also prevent you from trying to load a model that's not installed right away with an `ImportError` at the beginning. You can do this using the following commands.\n",
    "\n",
    "`import en_core_web_sm`\n",
    "\n",
    "`nlp = en_core_web_sm.load()`\n",
    "`doc = nlp(u\"This is a sentence.\")`\n",
    "\n",
    "This is also helpful for flexibility when writing tests that require loading a model. When the model is imported in this way, you can call Python's `importorskip()` method to only run a test if a specific model or package is installed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing and using your own models\n",
    "The point of this tutorial is to begin to teach you how to build and integrate your own models. [Here](https://spacy.io/usage/models) SpaCy covers the installation process from top to bottom, but I'll go into how to save and load custom models at the end of the post (or in another if this is too long) after we create one. If you already have one created and want to know how to integrate it/see SpaCy's tips for packaging a model for use, look [here](https://spacy.io/usage/saving-loading#models). If you already have a model and want to see how to use it in a production environment, look [here](https://spacy.io/usage/training#tips).\n",
    "\n",
    "## Ok, I have everything installed properly, but that seems like we're still using SpaCy's en_core_web_sm model. I want to build my own model.\n",
    "Yup - that was just the preliminary information for setup. Let's move onto training a new statistical model for named entity recognition through SpaCy's framework. \n",
    "\n",
    "### Basics\n",
    "SpaCy's models are statistical, which means that every time you want them to identify whether or not a word is a member of a named entity you've created, its making a prediction that's enabled by examples the model has seen during its training phase. To train the model, we'll need training data:\n",
    "1. examples of text\n",
    "2. labels we want the model to predict\n",
    "\n",
    "The model will be shown the unlabelled text and it will make a prediction based on what it's seen. __Because we know the correct answer, we can give the model feedback on its prediction through an _error gradient of the loss function_ that calculates the difference between the training example and the expected output.__ The greater the difference, the more significant the gradient and the updates to our model. Finding the loss function and integrating it into the training model will be the focus of the next post. \n",
    "\n",
    "The examples of text are __very important__. What circumstances you train your model on will determine its precision on generalized tasks you give it later. In order to make sure that the model is training on the right things, you need to give it __validation data__ in addition to the training data. \n",
    "\n",
    "### Formatting\n",
    "Before we go into SpaCy's `train` terminal command, let's look at the type of data that it expects. You can see an in-depth overview of the JSON format that it wants for training [here](https://spacy.io/api/annotation#json-input). In machine learning, the majority of the work is often just formatting the data in the correct manner. \n",
    "\n",
    "If you're in the same boat as me, the initial .json requirements of SpaCy's train commandline interface are a bit difficult to understand, especially in the context of a custom NER model. To cover the annotation specifics, I wrote a whole new post [here]() specifically tackling and explaining everything you need to do to get your training data up and running. \n",
    "\n",
    "### Training a Model using SpaCy's Command Line Interface "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "default"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
