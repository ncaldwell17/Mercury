{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NER v.2 - Training for Custom Entities on SpaCy\n",
    "\n",
    "The previous notebook handled the basics of using SpaCy's built-in entity recognition model to identify entities in any random string of words. This post will handle the creation of custom entities for any kind of unique task you want to use it for. At [Quiddity Solutions](https://www.quidditysolutions.com/), we use Statistical Language Modeling to identify specific, useful medical terminology and figures as part of our Treatment Matrix. This kind of useful information isn't readily available in a neat package off-the-shelf online. Therefore, we need to design our own custom model. Because a lot of NLP is very experimental and not yet mainstream, we began some of our experiments using [SpaCy](https://spacy.io/), a neat package designed by [Explosion](https://explosion.ai/), a German software company specializing in AI-related packages. Some of the initial research on what a custom, self-improving statistical language model to identify named entities would eventually look like was inspired by SpaCy's approach. You can see what we're currently working on at the Mercury [project website](https://ncaldwell17.github.io/Mercury/). \n",
    "\n",
    "Before I begin, make sure that this is the right place for you to start. What does your task data look like? What do you want your model to achieve? Do you have a finite number of examples you want it to look like? Is there a clear, structured pattern in the data that can be used to identify the entities? If that sounds like your data, you might be better suited to use __rule-based matching__ instead of training a model from scratch. You can find more information on that [here](https://spacy.io/usage/rule-based-matching). If your data is complex, you only have some limited examples, you want the system to be able to generalize across a variety of tasks, and instead of a clear, structured pattern, there are only clues in the data that you can use to train - you definitely want to train your own model. That's what this post is all about. \n",
    "\n",
    "I've found the best approach is a hybrid model, one that can handle both rules and context clues to achieve good accuracy. SpaCy's recently come out with a new option that lets you do this, which you can read about [here](https://spacy.io/usage/rule-based-matching#entityruler). In future posts, when I cover some of the precision pitfalls we encountered in designing Quiddity Solutions' flagship product, we'll start to get into the design and implementation of such a hybrid model. \n",
    "\n",
    "## I want to build a custom model, how do I start?\n",
    "Say you have a task like Quiddity's - you want to build your custom model but don't know where to begin. Let's start by installing SpaCy - they're the preÃ«minent off-the-shelf Python-based NER package out there. One unique thing about Spacy is that you'll be using a pretrained model for some of the initial work, which means the installation is a bit different from what you'll be used to when working with Python modules. In order to get it just right, you need to make sure that the model SpaCy has for your language is specifically downloaded and installed to the right directory. I'll detail the exact terminal command in the cell below, but its essential that you do this in the way described because it can cause all kinds of headaches otherwise. If you want more information on the installation process, you can go [here](https://spacy.io/usage/models). You needed to do this to achieve the results of the previous post, but I like reiterating things when I write code tutorials - I find it's hard to keep track of every little thing as we go, and it's helpful for those who skipped the first one. \n",
    "\n",
    "__NOTE:__ This tutorial assumes that you have already installed SpaCy on your computer - if you haven't, just input the following terminal command if you have pip enabled.<br>\n",
    "`pip install spacy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: en_core_web_sm==2.0.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz#egg=en_core_web_sm==2.0.0 in /Users/noahcg/anaconda3/lib/python3.6/site-packages (2.0.0)\n",
      "\u001b[33mYou are using pip version 18.0, however version 19.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\n",
      "\u001b[93m    Linking successful\u001b[0m\n",
      "    /Users/noahcg/anaconda3/lib/python3.6/site-packages/en_core_web_sm -->\n",
      "    /Users/noahcg/anaconda3/lib/python3.6/site-packages/spacy/data/en_core_web_sm\n",
      "\n",
      "    You can now load the model via spacy.load('en_core_web_sm')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ! indicates a terminal command for Jupyter notebooks\n",
    "# en_core_web_sm is the name of SpaCy's English model\n",
    "!python -m spacy download en_core_web_sm\n",
    "# python -m allows you to use the proceeding module as  \n",
    "#    if you had typed out its entire path."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that there's a little printout telling you that you can load the model via the `spacy.load('en_core_web_sm')` method and argument. That means that you still have to call it within whatever program you write. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "# load the pre-trained model \n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use all of `en_core_web_sm`'s capabilities just by typing the command `nlp()`. __NOTE__: There are four English models offered by SpaCy that offer a variety of features for NLP use. In this tutorial, we'll be using the smallest, the one we've already downloaded. If you want to see more on the additional three models, look [here](https://spacy.io/models/en).\n",
    "\n",
    "__NOTE2__: There's a variety of ways to import whatever model you want to work with as well - SpaCy recommends native imports for larger code bases to make it easier to integrate models with an existing build process and workflow. It'll also prevent you from trying to load a model that's not installed right away with an `ImportError` at the beginning. You can do this using the following commands.\n",
    "\n",
    "`import en_core_web_sm`\n",
    "\n",
    "`nlp = en_core_web_sm.load()`\n",
    "`doc = nlp(u\"This is a sentence.\")`\n",
    "\n",
    "This is also helpful for flexibility when writing tests that require loading a model. When the model is imported in this way, you can call Python's `importorskip()` method to only run a test if a specific model or package is installed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing and using your own models\n",
    "The point of this tutorial is to begin to teach you how to build and integrate your own models. [Here](https://spacy.io/usage/models) SpaCy covers the installation process from top to bottom, but I'll go into how to save and load custom models at the end of the post (or in another if this is too long) after we create one. If you already have one created and want to know how to integrate it/see SpaCy's tips for packaging a model for use, look [here](https://spacy.io/usage/saving-loading#models). If you already have a model and want to see how to use it in a production environment, look [here](https://spacy.io/usage/training#tips).\n",
    "\n",
    "## Ok, I have everything installed properly, but that seems like we're still using SpaCy's en_core_web_sm model. I want to build my own model.\n",
    "Yup - that was just the preliminary information for setup. Let's move onto training a new statistical model for named entity recognition through SpaCy's framework. \n",
    "\n",
    "### Basics\n",
    "SpaCy's models are statistical, which means that every time you want them to identify whether or not a word is a member of a named entity you've created, its making a prediction that's enabled by examples the model has seen during its training phase. To train the model, we'll need training data:\n",
    "1. examples of text\n",
    "2. labels we want the model to predict\n",
    "\n",
    "The model will be shown the unlabelled text and it will make a prediction based on what it's seen. __Because we know the correct answer, we can give the model feedback on its prediction through an _error gradient of the loss function_ that calculates the difference between the training example and the expected output.__ The greater the difference, the more significant the gradient and the updates to our model. Finding the loss function and integrating it into the training model will be the focus of the next post. \n",
    "\n",
    "The examples of text are __very important__. What circumstances you train your model on will determine its precision on generalized tasks you give it later. In order to make sure that the model is training on the right things, you need to give it __validation data__ in addition to the training data. \n",
    "\n",
    "### Formatting\n",
    "Before we go into SpaCy's `train` terminal command, let's look at the type of data that it expects. You can see an in-depth overview of the JSON format that it wants for training [here](https://spacy.io/api/annotation#json-input). In machine learning, the majority of the work is often just formatting the data in the correct manner. \n",
    "\n",
    "If you're in the same boat as me, the initial .json requirements of SpaCy's train commandline interface are a bit difficult to understand, especially in the context of a custom NER model. To cover the annotation specifics, I wrote a whole new post [here]() specifically tackling and explaining everything you need to do to get your training data up and running. \n",
    "\n",
    "### Training a Model using SpaCy's Command Line Interface "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "default"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
